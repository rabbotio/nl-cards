[
    {
        "front": {
            "title": "Accuracy"
        },
        "back": {
            "math": "\\text{Accuracy} = \\frac{TP+TN}{TP+TN+FP+FN}",
            "desc": "The fraction of predictions that a classification model got right.",
            "bullets": [
                "T = True",
                "F = False"
            ],
            "bullets_extra": [
                "P = Positives",
                "N = Negatives"
            ]
        }
    },
    {
        "front": {
            "title": "Precision"
        },
        "back": {
            "math": "\\text{Precision} = \\frac{TP}{TP+FP}",
            "desc": "A metric for classification models. Precision identifies the frequency with which a model was correct when predicting the positive class.",
            "bullets": [
                "T = True",
                "F = False"
            ],
            "bullets_extra": [
                "P = Positives",
                "N = Negatives"
            ]
        }
    },
    {
        "front": {
            "title": "Recall"
        },
        "back": {
            "math": "\\text{Recall} = \\frac{\\text{TP}} {\\text{TP} + \\text{FN}}",
            "desc": "A metric for classification models that answers the following question: Out of all the possible positive labels, how many did the model correctly identify?",
            "bullets": [
                "T = True",
                "F = False"
            ],
            "bullets_extra": [
                "P = Positives",
                "N = Negatives"
            ]
        }
    },
    {
        "front": {
            "title": "L<sub>2</sub> Regularization"
        },
        "back": {
            "desc": "A type of regularization that penalizes weights in proportion to the sum of the squares of the weights.",
            "math": "L_2\\text{ Regularization} = ||\\boldsymbol w||_2^2 = {w_1^2 + w_2^2 + ... + w_n^2}",
            "bullets": [
                "Drive outlier weights (high positive or low negative values) closer to 0 but not quite to 0.",
                "Always improves generalization in linear models."
            ]
        }
    },
    {
        "front": {
            "title": "Supervised Machine Learning",
            "image": "./ml/img/supervised.svg"
        },
        "back": {
            "desc": "Training a <b>model</b> from input data and its corresponding labels.<br>Provide answers for never-before-seen questions on the same topic",
            "math": "\\text{Labeled Data} \\xrightarrow[\\text{features x}]{\\text{labels y}} \\text{Predictive Model}",
            "bullets": [
                "<dfn>\\[x\\]</dfn> is feature.<br/>",
                "<dfn>\\[y\\]</dfn> is label."
            ]
        }
    },
    {
        "front": {
            "title": "Linear Regression",
            "image": "./ml/img/supervised.svg"
        },
        "back": {
            "desc": "A type of regression model that outputs a continuous value from a linear combination of input features.",
            "math": "y' = b + w_1x_1",
            "bullets": [
                "<dfn>\\[y'\\]</dfn> is the predicted label (a desired output).",
                "<dfn>\\[b\\]</dfn> (or <dfn>\\[w_0\\]</dfn>) is the bias (the y-intercept)",
                "<dfn>\\[w_1\\]</dfn> is the weight (slope) of feature 1.",
                "<dfn>\\[x_1\\]</dfn>  is a feature (a known input)."
            ]
        }
    }
]